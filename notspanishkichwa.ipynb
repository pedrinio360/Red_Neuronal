{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a82ad5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:20.162782Z",
     "iopub.status.busy": "2023-03-19T17:53:20.162277Z",
     "iopub.status.idle": "2023-03-19T17:53:30.199736Z",
     "shell.execute_reply": "2023-03-19T17:53:30.198436Z"
    },
    "papermill": {
     "duration": 10.05235,
     "end_time": "2023-03-19T17:53:30.203159",
     "exception": false,
     "start_time": "2023-03-19T17:53:20.150809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandronogales/anaconda3/envs/traductor/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-06 22:34:56.738483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce97b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.216258Z",
     "iopub.status.busy": "2023-03-19T17:53:30.214571Z",
     "iopub.status.idle": "2023-03-19T17:53:30.246329Z",
     "shell.execute_reply": "2023-03-19T17:53:30.245072Z"
    },
    "papermill": {
     "duration": 0.040737,
     "end_time": "2023-03-19T17:53:30.249132",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.208395",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding = 'utf8') as f:\n",
    "        data = f.read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "spanish_sentences = load_data('data/input/spanish_vocab.txt')\n",
    "kichwa_sentences = load_data('data/input/kichwa_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edf6fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.261003Z",
     "iopub.status.busy": "2023-03-19T17:53:30.260206Z",
     "iopub.status.idle": "2023-03-19T17:53:30.269237Z",
     "shell.execute_reply": "2023-03-19T17:53:30.268173Z"
    },
    "papermill": {
     "duration": 0.017824,
     "end_time": "2023-03-19T17:53:30.271820",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.253996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pares_oraciones = []\n",
    "for index, item in enumerate(spanish_sentences, start=0):\n",
    "    spanish = item\n",
    "    kichwa = \"[start] \" + kichwa_sentences[index] + \" [end]\"\n",
    "    pares_oraciones.append((spanish, kichwa))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0097c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.283302Z",
     "iopub.status.busy": "2023-03-19T17:53:30.282506Z",
     "iopub.status.idle": "2023-03-19T17:53:30.292821Z",
     "shell.execute_reply": "2023-03-19T17:53:30.291523Z"
    },
    "papermill": {
     "duration": 0.018476,
     "end_time": "2023-03-19T17:53:30.294975",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.276499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.shuffle(pares_oraciones)\n",
    "num_pares_validar = int(0.1 * len(pares_oraciones))\n",
    "num_pares_train = int(0.9 * len(pares_oraciones))\n",
    "pares_train = pares_oraciones[:num_pares_train]\n",
    "pares_validar = pares_oraciones[num_pares_train:num_pares_train + num_pares_validar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959937f5",
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.306012Z",
     "iopub.status.busy": "2023-03-19T17:53:30.305616Z",
     "iopub.status.idle": "2023-03-19T17:53:31.060996Z",
     "shell.execute_reply": "2023-03-19T17:53:31.058941Z"
    },
    "papermill": {
     "duration": 0.766845,
     "end_time": "2023-03-19T17:53:31.066488",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.299643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "modificar_chars = string.punctuation + \"Â¿\"\n",
    "modificar_chars = modificar_chars.replace(\"[\", \"\")\n",
    "modificar_chars = modificar_chars.replace(\"]\", \"\")\n",
    "\n",
    "len_sentences = 7\n",
    "num_vocab = 5000\n",
    "\n",
    "def get_standardization(text):\n",
    "    texto = tf.strings.lower(text)\n",
    "    return tf.strings.regex_replace(\n",
    "        texto, f\"[{re.escape(modificar_chars)}]\", \"\")\n",
    "\n",
    "texto_source_vectorizado = layers.TextVectorization(\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = len_sentences,\n",
    "    max_tokens = num_vocab,\n",
    "    standardize = get_standardization\n",
    ")\n",
    "texto_target_vectorizado = layers.TextVectorization(\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = len_sentences + 1,\n",
    "    max_tokens = num_vocab,\n",
    "    standardize = get_standardization\n",
    ")\n",
    "\n",
    "textos_train_spanish = [par[0] for par in pares_train]\n",
    "textos_train_kichwa = [par[1] for par in pares_train]\n",
    "texto_source_vectorizado.adapt(textos_train_spanish)\n",
    "texto_target_vectorizado.adapt(textos_train_kichwa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64723905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.082835Z",
     "iopub.status.busy": "2023-03-19T17:53:31.082011Z",
     "iopub.status.idle": "2023-03-19T17:53:31.628318Z",
     "shell.execute_reply": "2023-03-19T17:53:31.626766Z"
    },
    "papermill": {
     "duration": 0.558046,
     "end_time": "2023-03-19T17:53:31.630941",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.072895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entradas['spanish'].shape: (64, 7)\n",
      "entradas['kichwa'].shape: (64, 7)\n",
      "salidas.shape: (64, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 22:35:06.870005: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def set_format(spanish, kichwa):\n",
    "    spanish = texto_source_vectorizado(spanish) \n",
    "    kichwa = texto_target_vectorizado(kichwa)\n",
    "    return (\n",
    "        {\n",
    "            \"spanish\": spanish,\n",
    "            \"kichwa\": kichwa[:, :-1],\n",
    "        }, \n",
    "        kichwa[:, 1:]\n",
    "    )\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    textos_spanish, textos_kichwa = zip(*pairs)\n",
    "    textos_spanish = list(textos_spanish)\n",
    "    textos_kichwa = list(textos_kichwa)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((textos_spanish, textos_kichwa))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(set_format, num_parallel_calls=4)\n",
    "\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "dataset_train = make_dataset(pares_train)\n",
    "dataset_validacion = make_dataset(pares_validar)\n",
    "\n",
    "for entradas, salidas in dataset_train.take(1):\n",
    "    print(f\"entradas['spanish'].shape: {entradas['spanish'].shape}\")\n",
    "    print(f\"entradas['kichwa'].shape: {entradas['kichwa'].shape}\")\n",
    "    print(f\"salidas.shape: {salidas.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254156a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.643641Z",
     "iopub.status.busy": "2023-03-19T17:53:31.642675Z",
     "iopub.status.idle": "2023-03-19T17:53:31.653628Z",
     "shell.execute_reply": "2023-03-19T17:53:31.652257Z"
    },
    "papermill": {
     "duration": 0.020517,
     "end_time": "2023-03-19T17:53:31.656489",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.635972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderTrans(layers.Layer):\n",
    "\n",
    "    def __init__(self, num_heads, dense_dim, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.dense_dim = dense_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attention = layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(\n",
    "                dense_dim, \n",
    "                activation = \"relu\"\n",
    "            ),\n",
    "            layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, entradas, mask = None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_salida = self.attention(entradas, entradas, attention_mask = mask)\n",
    "        proj_entrada = self.layernorm_1(entradas + attention_salida)\n",
    "        proj_salida = self.dense_proj(proj_entrada)\n",
    "\n",
    "        return self.layernorm_2(proj_entrada + proj_salida)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a79e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.667833Z",
     "iopub.status.busy": "2023-03-19T17:53:31.667387Z",
     "iopub.status.idle": "2023-03-19T17:53:31.683582Z",
     "shell.execute_reply": "2023-03-19T17:53:31.682641Z"
    },
    "papermill": {
     "duration": 0.024937,
     "end_time": "2023-03-19T17:53:31.686249",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.661312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderTrans(layers.Layer):\n",
    "    def __init__(self, num_heads, dense_dim, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.dense_dim = dense_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation = \"relu\"),\n",
    "             layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_mask_attention_causal(self, entradas):\n",
    "        shape_entrada = tf.shape(entradas)\n",
    "        batch_size, len_sequence = shape_entrada[0], shape_entrada[1]\n",
    "        i = tf.range(len_sequence)[:, tf.newaxis]\n",
    "        j = tf.range(len_sequence)\n",
    "        mask = tf.cast(i >= j, dtype = \"int32\")\n",
    "        mask = tf.reshape(mask, (1, shape_entrada[1], shape_entrada[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype = tf.int32)], axis = 0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, entradas, salidas_encoder, mask = None):\n",
    "        mask_causal = self.get_mask_attention_causal(entradas)\n",
    "        if mask is not None:\n",
    "            mask_padding = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            mask_padding = tf.minimum(mask_padding, mask_causal)\n",
    "        attention_salida_1 = self.attention_1(\n",
    "            query = entradas,\n",
    "            value = entradas,\n",
    "            key = entradas,\n",
    "            attention_mask = mask_causal)\n",
    "        attention_salida_1 = self.layernorm_1(entradas + attention_salida_1)\n",
    "        attention_salida_2 = self.attention_2(\n",
    "            query = attention_salida_1,\n",
    "            value = salidas_encoder,\n",
    "            key = salidas_encoder,\n",
    "            attention_mask = mask_padding,\n",
    "        )\n",
    "        attention_salida_2 = self.layernorm_2(\n",
    "            attention_salida_1 + attention_salida_2)\n",
    "        proj_salida = self.dense_proj(attention_salida_2)\n",
    "\n",
    "        return self.layernorm_3(attention_salida_2 + proj_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c9a967a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.697314Z",
     "iopub.status.busy": "2023-03-19T17:53:31.696910Z",
     "iopub.status.idle": "2023-03-19T17:53:31.706902Z",
     "shell.execute_reply": "2023-03-19T17:53:31.705659Z"
    },
    "papermill": {
     "duration": 0.018087,
     "end_time": "2023-03-19T17:53:31.709032",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.690945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "\n",
    "    def __init__(self, dim_entrada, dim_salida, len_sentences, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_dim = dim_entrada\n",
    "        self.output_dim = dim_salida\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim = dim_entrada, output_dim = dim_salida)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim = len_sentences, output_dim = dim_salida)\n",
    "        self.sequence_length = len_sentences\n",
    "\n",
    "    def call(self, entradas):\n",
    "        limite = tf.shape(entradas)[-1]\n",
    "        posiciones = tf.range(start = 0, limit = limite, delta = 1)\n",
    "        tokens_embedded = self.token_embeddings(entradas)\n",
    "        posiciones_embedded = self.position_embeddings(posiciones)\n",
    "        return tokens_embedded + posiciones_embedded\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ed0383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.720389Z",
     "iopub.status.busy": "2023-03-19T17:53:31.719425Z",
     "iopub.status.idle": "2023-03-19T17:53:32.750217Z",
     "shell.execute_reply": "2023-03-19T17:53:32.748923Z"
    },
    "papermill": {
     "duration": 1.039676,
     "end_time": "2023-03-19T17:53:32.753394",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.713718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "\n",
    "entradas_encoder = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEncoding(num_vocab, embed_dim, len_sentences)(entradas_encoder)\n",
    "salidas_encoder = EncoderTrans(num_heads, dense_dim, embed_dim )(x)\n",
    "\n",
    "entradas_decoder = keras.Input(shape=(None,), dtype=\"int64\", name=\"kichwa\")\n",
    "x = PositionalEncoding(num_vocab, embed_dim, len_sentences,)(entradas_decoder)\n",
    "x = DecoderTrans(num_heads, dense_dim, embed_dim )(x, salidas_encoder)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "salidas_decoder = layers.Dense(num_vocab, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([entradas_encoder, entradas_decoder], salidas_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b746ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:32.765559Z",
     "iopub.status.busy": "2023-03-19T17:53:32.764327Z",
     "iopub.status.idle": "2023-03-19T19:00:47.433546Z",
     "shell.execute_reply": "2023-03-19T19:00:47.431963Z"
    },
    "papermill": {
     "duration": 4034.678285,
     "end_time": "2023-03-19T19:00:47.436499",
     "exception": false,
     "start_time": "2023-03-19T17:53:32.758214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " spanish (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " kichwa (InputLayer)         [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " positional_encoding (Posit  (None, None, 256)            1281792   ['spanish[0][0]']             \n",
      " ionalEncoding)                                                                                   \n",
      "                                                                                                  \n",
      " positional_encoding_1 (Pos  (None, None, 256)            1281792   ['kichwa[0][0]']              \n",
      " itionalEncoding)                                                                                 \n",
      "                                                                                                  \n",
      " encoder_trans (EncoderTran  (None, None, 256)            3155456   ['positional_encoding[0][0]'] \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " decoder_trans (DecoderTran  (None, None, 256)            5259520   ['positional_encoding_1[0][0]'\n",
      " s)                                                                 , 'encoder_trans[0][0]']      \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 256)            0         ['decoder_trans[0][0]']       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, None, 5000)           1285000   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12263560 (46.78 MB)\n",
      "Trainable params: 12263560 (46.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "52/52 [==============================] - 50s 823ms/step - loss: 4.8847 - accuracy: 0.4273 - val_loss: 4.3096 - val_accuracy: 0.4622\n",
      "Epoch 2/200\n",
      "52/52 [==============================] - 42s 803ms/step - loss: 4.3641 - accuracy: 0.4479 - val_loss: 4.2239 - val_accuracy: 0.4646\n",
      "Epoch 3/200\n",
      "52/52 [==============================] - 47s 908ms/step - loss: 3.9421 - accuracy: 0.4747 - val_loss: 4.0827 - val_accuracy: 0.4790\n",
      "Epoch 4/200\n",
      "52/52 [==============================] - 43s 828ms/step - loss: 3.6069 - accuracy: 0.5055 - val_loss: 3.9588 - val_accuracy: 0.5060\n",
      "Epoch 5/200\n",
      "52/52 [==============================] - 42s 796ms/step - loss: 3.2891 - accuracy: 0.5390 - val_loss: 3.8430 - val_accuracy: 0.5150\n",
      "Epoch 6/200\n",
      "52/52 [==============================] - 42s 815ms/step - loss: 2.9654 - accuracy: 0.5727 - val_loss: 3.8693 - val_accuracy: 0.5186\n",
      "Epoch 7/200\n",
      "52/52 [==============================] - 40s 773ms/step - loss: 2.6643 - accuracy: 0.6101 - val_loss: 3.8000 - val_accuracy: 0.5288\n",
      "Epoch 8/200\n",
      "52/52 [==============================] - 40s 779ms/step - loss: 2.3698 - accuracy: 0.6480 - val_loss: 3.6478 - val_accuracy: 0.5474\n",
      "Epoch 9/200\n",
      "52/52 [==============================] - 38s 734ms/step - loss: 2.0957 - accuracy: 0.6854 - val_loss: 3.6626 - val_accuracy: 0.5426\n",
      "Epoch 10/200\n",
      "52/52 [==============================] - 40s 779ms/step - loss: 1.8753 - accuracy: 0.7226 - val_loss: 3.6181 - val_accuracy: 0.5546\n",
      "Epoch 11/200\n",
      "52/52 [==============================] - 39s 747ms/step - loss: 1.6290 - accuracy: 0.7610 - val_loss: 3.5296 - val_accuracy: 0.5582\n",
      "Epoch 12/200\n",
      "52/52 [==============================] - 39s 751ms/step - loss: 1.4246 - accuracy: 0.7905 - val_loss: 3.5461 - val_accuracy: 0.5588\n",
      "Epoch 13/200\n",
      "52/52 [==============================] - 39s 753ms/step - loss: 1.2359 - accuracy: 0.8227 - val_loss: 3.5095 - val_accuracy: 0.5618\n",
      "Epoch 14/200\n",
      "52/52 [==============================] - 40s 774ms/step - loss: 1.1370 - accuracy: 0.8372 - val_loss: 8.5943 - val_accuracy: 0.3459\n",
      "Epoch 15/200\n",
      "52/52 [==============================] - 41s 785ms/step - loss: 1.1443 - accuracy: 0.8453 - val_loss: 3.5284 - val_accuracy: 0.5588\n",
      "Epoch 16/200\n",
      "52/52 [==============================] - 39s 756ms/step - loss: 0.8260 - accuracy: 0.8872 - val_loss: 3.5240 - val_accuracy: 0.5695\n",
      "Epoch 17/200\n",
      "52/52 [==============================] - 39s 741ms/step - loss: 0.7198 - accuracy: 0.9048 - val_loss: 3.5104 - val_accuracy: 0.5635\n",
      "Epoch 18/200\n",
      "52/52 [==============================] - 42s 799ms/step - loss: 0.6021 - accuracy: 0.9224 - val_loss: 3.4975 - val_accuracy: 0.5683\n",
      "Epoch 19/200\n",
      "52/52 [==============================] - 42s 815ms/step - loss: 0.5011 - accuracy: 0.9396 - val_loss: 3.5223 - val_accuracy: 0.5665\n",
      "Epoch 20/200\n",
      "52/52 [==============================] - 41s 779ms/step - loss: 0.4171 - accuracy: 0.9521 - val_loss: 3.5559 - val_accuracy: 0.5546\n",
      "Epoch 21/200\n",
      "52/52 [==============================] - 39s 760ms/step - loss: 0.3413 - accuracy: 0.9608 - val_loss: 3.4935 - val_accuracy: 0.5743\n",
      "Epoch 22/200\n",
      "52/52 [==============================] - 38s 733ms/step - loss: 0.4704 - accuracy: 0.9478 - val_loss: 4.0856 - val_accuracy: 0.4796\n",
      "Epoch 23/200\n",
      "52/52 [==============================] - 39s 750ms/step - loss: 0.3020 - accuracy: 0.9634 - val_loss: 3.5416 - val_accuracy: 0.5791\n",
      "Epoch 24/200\n",
      "52/52 [==============================] - 37s 715ms/step - loss: 0.3684 - accuracy: 0.9529 - val_loss: 3.5090 - val_accuracy: 0.5743\n",
      "Epoch 25/200\n",
      "52/52 [==============================] - 39s 752ms/step - loss: 0.2071 - accuracy: 0.9749 - val_loss: 3.5525 - val_accuracy: 0.5689\n",
      "Epoch 26/200\n",
      "52/52 [==============================] - 39s 759ms/step - loss: 0.1603 - accuracy: 0.9828 - val_loss: 3.6028 - val_accuracy: 0.5683\n",
      "Epoch 27/200\n",
      "52/52 [==============================] - 39s 747ms/step - loss: 0.1223 - accuracy: 0.9859 - val_loss: 3.5867 - val_accuracy: 0.5713\n",
      "Epoch 28/200\n",
      "52/52 [==============================] - 43s 833ms/step - loss: 0.2013 - accuracy: 0.9732 - val_loss: 7.3593 - val_accuracy: 0.4808\n",
      "Epoch 29/200\n",
      "52/52 [==============================] - 45s 863ms/step - loss: 0.2318 - accuracy: 0.9742 - val_loss: 3.6174 - val_accuracy: 0.5779\n",
      "Epoch 30/200\n",
      "52/52 [==============================] - 42s 815ms/step - loss: 0.2125 - accuracy: 0.9726 - val_loss: 3.6565 - val_accuracy: 0.5749\n",
      "Epoch 31/200\n",
      "52/52 [==============================] - 39s 760ms/step - loss: 0.0827 - accuracy: 0.9895 - val_loss: 3.6859 - val_accuracy: 0.5743\n",
      "Epoch 32/200\n",
      "52/52 [==============================] - 40s 767ms/step - loss: 0.0815 - accuracy: 0.9894 - val_loss: 3.7074 - val_accuracy: 0.5767\n",
      "Epoch 33/200\n",
      "52/52 [==============================] - 39s 749ms/step - loss: 0.0601 - accuracy: 0.9921 - val_loss: 3.7368 - val_accuracy: 0.5767\n",
      "Epoch 34/200\n",
      "52/52 [==============================] - 40s 763ms/step - loss: 0.0782 - accuracy: 0.9876 - val_loss: 3.8145 - val_accuracy: 0.5665\n",
      "Epoch 35/200\n",
      "52/52 [==============================] - 41s 783ms/step - loss: 0.0605 - accuracy: 0.9906 - val_loss: 3.7658 - val_accuracy: 0.5767\n",
      "Epoch 36/200\n",
      "52/52 [==============================] - 39s 745ms/step - loss: 0.0559 - accuracy: 0.9908 - val_loss: 3.7851 - val_accuracy: 0.5755\n",
      "Epoch 37/200\n",
      "52/52 [==============================] - 42s 804ms/step - loss: 0.1933 - accuracy: 0.9705 - val_loss: 3.7999 - val_accuracy: 0.5797\n",
      "Epoch 38/200\n",
      "52/52 [==============================] - 39s 744ms/step - loss: 0.0504 - accuracy: 0.9914 - val_loss: 3.8037 - val_accuracy: 0.5737\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 37s 707ms/step - loss: 0.0372 - accuracy: 0.9936 - val_loss: 3.7965 - val_accuracy: 0.5809\n",
      "Epoch 40/200\n",
      "52/52 [==============================] - 37s 710ms/step - loss: 0.0318 - accuracy: 0.9948 - val_loss: 3.8811 - val_accuracy: 0.5773\n",
      "Epoch 41/200\n",
      "52/52 [==============================] - 37s 716ms/step - loss: 0.0371 - accuracy: 0.9930 - val_loss: 4.1630 - val_accuracy: 0.4928\n",
      "Epoch 42/200\n",
      "52/52 [==============================] - 37s 713ms/step - loss: 0.0645 - accuracy: 0.9891 - val_loss: 3.9140 - val_accuracy: 0.5761\n",
      "Epoch 43/200\n",
      "52/52 [==============================] - 36s 700ms/step - loss: 0.0336 - accuracy: 0.9945 - val_loss: 3.8748 - val_accuracy: 0.5791\n",
      "Epoch 44/200\n",
      "52/52 [==============================] - 37s 710ms/step - loss: 0.0435 - accuracy: 0.9921 - val_loss: 3.9618 - val_accuracy: 0.5755\n",
      "Epoch 45/200\n",
      "52/52 [==============================] - 37s 707ms/step - loss: 0.0331 - accuracy: 0.9935 - val_loss: 3.9630 - val_accuracy: 0.5683\n",
      "Epoch 46/200\n",
      "52/52 [==============================] - 36s 703ms/step - loss: 0.0706 - accuracy: 0.9872 - val_loss: 3.9489 - val_accuracy: 0.5791\n",
      "Epoch 47/200\n",
      "52/52 [==============================] - 37s 705ms/step - loss: 0.0442 - accuracy: 0.9912 - val_loss: 3.9754 - val_accuracy: 0.5731\n",
      "Epoch 48/200\n",
      "52/52 [==============================] - 36s 696ms/step - loss: 0.0353 - accuracy: 0.9932 - val_loss: 4.0208 - val_accuracy: 0.5725\n",
      "Epoch 49/200\n",
      "52/52 [==============================] - 36s 694ms/step - loss: 0.0401 - accuracy: 0.9918 - val_loss: 3.9971 - val_accuracy: 0.5773\n",
      "Epoch 50/200\n",
      "52/52 [==============================] - 36s 697ms/step - loss: 0.0337 - accuracy: 0.9935 - val_loss: 4.0599 - val_accuracy: 0.5767\n",
      "Epoch 51/200\n",
      "52/52 [==============================] - 36s 696ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 4.0386 - val_accuracy: 0.5635\n",
      "Epoch 52/200\n",
      "52/52 [==============================] - 36s 689ms/step - loss: 0.0332 - accuracy: 0.9939 - val_loss: 4.0687 - val_accuracy: 0.5719\n",
      "Epoch 53/200\n",
      "52/52 [==============================] - 36s 689ms/step - loss: 0.0282 - accuracy: 0.9938 - val_loss: 4.0868 - val_accuracy: 0.5737\n",
      "Epoch 54/200\n",
      "52/52 [==============================] - 37s 712ms/step - loss: 0.0271 - accuracy: 0.9943 - val_loss: 4.0811 - val_accuracy: 0.5743\n",
      "Epoch 55/200\n",
      "52/52 [==============================] - 37s 701ms/step - loss: 0.0211 - accuracy: 0.9956 - val_loss: 4.0737 - val_accuracy: 0.5797\n",
      "Epoch 56/200\n",
      "52/52 [==============================] - 36s 693ms/step - loss: 0.0216 - accuracy: 0.9961 - val_loss: 4.1045 - val_accuracy: 0.5809\n",
      "Epoch 57/200\n",
      "52/52 [==============================] - 37s 704ms/step - loss: 0.0267 - accuracy: 0.9945 - val_loss: 4.0872 - val_accuracy: 0.5755\n",
      "Epoch 58/200\n",
      "52/52 [==============================] - 35s 683ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 4.0838 - val_accuracy: 0.5815\n",
      "Epoch 59/200\n",
      "52/52 [==============================] - 35s 681ms/step - loss: 0.0260 - accuracy: 0.9951 - val_loss: 4.1246 - val_accuracy: 0.5779\n",
      "Epoch 60/200\n",
      "52/52 [==============================] - 36s 696ms/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 4.0850 - val_accuracy: 0.5821\n",
      "Epoch 61/200\n",
      "52/52 [==============================] - 36s 686ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 4.1263 - val_accuracy: 0.5821\n",
      "Epoch 62/200\n",
      "52/52 [==============================] - 35s 682ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 4.1682 - val_accuracy: 0.5803\n",
      "Epoch 63/200\n",
      "52/52 [==============================] - 35s 679ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 4.0973 - val_accuracy: 0.5737\n",
      "Epoch 64/200\n",
      "52/52 [==============================] - 36s 689ms/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 4.1590 - val_accuracy: 0.5851\n",
      "Epoch 65/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 4.1693 - val_accuracy: 0.5845\n",
      "Epoch 66/200\n",
      "52/52 [==============================] - 36s 696ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 4.1063 - val_accuracy: 0.5845\n",
      "Epoch 67/200\n",
      "52/52 [==============================] - 35s 678ms/step - loss: 0.0233 - accuracy: 0.9953 - val_loss: 4.2361 - val_accuracy: 0.5815\n",
      "Epoch 68/200\n",
      "52/52 [==============================] - 35s 677ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 4.2305 - val_accuracy: 0.5833\n",
      "Epoch 69/200\n",
      "52/52 [==============================] - 36s 687ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 4.2123 - val_accuracy: 0.5683\n",
      "Epoch 70/200\n",
      "52/52 [==============================] - 36s 688ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 4.1935 - val_accuracy: 0.5827\n",
      "Epoch 71/200\n",
      "52/52 [==============================] - 35s 677ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 4.1928 - val_accuracy: 0.5827\n",
      "Epoch 72/200\n",
      "52/52 [==============================] - 36s 683ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 4.2089 - val_accuracy: 0.5827\n",
      "Epoch 73/200\n",
      "52/52 [==============================] - 36s 686ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 4.2823 - val_accuracy: 0.5773\n",
      "Epoch 74/200\n",
      "52/52 [==============================] - 36s 699ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 4.2688 - val_accuracy: 0.5821\n",
      "Epoch 75/200\n",
      "52/52 [==============================] - 36s 689ms/step - loss: 0.0289 - accuracy: 0.9939 - val_loss: 4.1862 - val_accuracy: 0.5815\n",
      "Epoch 76/200\n",
      "52/52 [==============================] - 35s 675ms/step - loss: 0.0792 - accuracy: 0.9860 - val_loss: 4.0953 - val_accuracy: 0.5785\n",
      "Epoch 77/200\n",
      "52/52 [==============================] - 36s 687ms/step - loss: 0.0289 - accuracy: 0.9936 - val_loss: 4.2499 - val_accuracy: 0.5797\n",
      "Epoch 78/200\n",
      "52/52 [==============================] - 36s 692ms/step - loss: 0.0364 - accuracy: 0.9922 - val_loss: 4.2082 - val_accuracy: 0.5719\n",
      "Epoch 79/200\n",
      "52/52 [==============================] - 36s 685ms/step - loss: 0.0278 - accuracy: 0.9939 - val_loss: 4.2290 - val_accuracy: 0.5749\n",
      "Epoch 80/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0447 - accuracy: 0.9908 - val_loss: 4.2014 - val_accuracy: 0.5689\n",
      "Epoch 81/200\n",
      "52/52 [==============================] - 35s 680ms/step - loss: 0.0316 - accuracy: 0.9936 - val_loss: 4.1739 - val_accuracy: 0.5779\n",
      "Epoch 82/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 4.2399 - val_accuracy: 0.5749\n",
      "Epoch 83/200\n",
      "52/52 [==============================] - 35s 683ms/step - loss: 0.0279 - accuracy: 0.9947 - val_loss: 4.2914 - val_accuracy: 0.5773\n",
      "Epoch 84/200\n",
      "52/52 [==============================] - 36s 691ms/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 4.2491 - val_accuracy: 0.5809\n",
      "Epoch 85/200\n",
      "52/52 [==============================] - 35s 683ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 4.2997 - val_accuracy: 0.5749\n",
      "Epoch 86/200\n",
      "52/52 [==============================] - 35s 681ms/step - loss: 0.0295 - accuracy: 0.9944 - val_loss: 4.2477 - val_accuracy: 0.5755\n",
      "Epoch 87/200\n",
      "52/52 [==============================] - 36s 693ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: 4.2074 - val_accuracy: 0.5767\n",
      "Epoch 88/200\n",
      "52/52 [==============================] - 36s 696ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 4.3337 - val_accuracy: 0.5791\n",
      "Epoch 89/200\n",
      "52/52 [==============================] - 35s 681ms/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 4.2866 - val_accuracy: 0.5731\n",
      "Epoch 90/200\n",
      "52/52 [==============================] - 36s 685ms/step - loss: 0.0216 - accuracy: 0.9955 - val_loss: 4.3178 - val_accuracy: 0.5797\n",
      "Epoch 91/200\n",
      "52/52 [==============================] - 35s 681ms/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 4.4044 - val_accuracy: 0.5528\n",
      "Epoch 92/200\n",
      "52/52 [==============================] - 35s 684ms/step - loss: 0.1095 - accuracy: 0.9824 - val_loss: 4.2427 - val_accuracy: 0.5815\n",
      "Epoch 93/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 4.3359 - val_accuracy: 0.5839\n",
      "Epoch 94/200\n",
      "52/52 [==============================] - 36s 685ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 4.3186 - val_accuracy: 0.5827\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 35s 672ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 4.3014 - val_accuracy: 0.5857\n",
      "Epoch 96/200\n",
      "52/52 [==============================] - 36s 695ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 4.3383 - val_accuracy: 0.5839\n",
      "Epoch 97/200\n",
      "52/52 [==============================] - 36s 685ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 4.3617 - val_accuracy: 0.5809\n",
      "Epoch 98/200\n",
      "52/52 [==============================] - 36s 689ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 4.3617 - val_accuracy: 0.5797\n",
      "Epoch 99/200\n",
      "52/52 [==============================] - 35s 673ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 4.4104 - val_accuracy: 0.5827\n",
      "Epoch 100/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 4.4088 - val_accuracy: 0.5785\n",
      "Epoch 101/200\n",
      "52/52 [==============================] - 36s 685ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 4.4064 - val_accuracy: 0.5857\n",
      "Epoch 102/200\n",
      "52/52 [==============================] - 36s 691ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 4.3707 - val_accuracy: 0.5815\n",
      "Epoch 103/200\n",
      "52/52 [==============================] - 35s 674ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 4.4169 - val_accuracy: 0.5827\n",
      "Epoch 104/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 4.4225 - val_accuracy: 0.5851\n",
      "Epoch 105/200\n",
      "52/52 [==============================] - 36s 694ms/step - loss: 0.0301 - accuracy: 0.9939 - val_loss: 4.3418 - val_accuracy: 0.5881\n",
      "Epoch 106/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 4.2371 - val_accuracy: 0.5833\n",
      "Epoch 107/200\n",
      "52/52 [==============================] - 36s 684ms/step - loss: 0.0336 - accuracy: 0.9936 - val_loss: 4.8195 - val_accuracy: 0.4898\n",
      "Epoch 108/200\n",
      "52/52 [==============================] - 38s 725ms/step - loss: 0.0636 - accuracy: 0.9901 - val_loss: 4.2452 - val_accuracy: 0.5767\n",
      "Epoch 109/200\n",
      "52/52 [==============================] - 38s 725ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 4.2722 - val_accuracy: 0.5809\n",
      "Epoch 110/200\n",
      "52/52 [==============================] - 36s 700ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 4.3434 - val_accuracy: 0.5785\n",
      "Epoch 111/200\n",
      "52/52 [==============================] - 38s 740ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 4.3982 - val_accuracy: 0.5791\n",
      "Epoch 112/200\n",
      "52/52 [==============================] - 35s 677ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 4.4307 - val_accuracy: 0.5749\n",
      "Epoch 113/200\n",
      "52/52 [==============================] - 49s 954ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 4.4991 - val_accuracy: 0.5773\n",
      "Epoch 114/200\n",
      "52/52 [==============================] - 42s 802ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 4.4156 - val_accuracy: 0.5785\n",
      "Epoch 115/200\n",
      "52/52 [==============================] - 38s 729ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 4.4591 - val_accuracy: 0.5851\n",
      "Epoch 116/200\n",
      "52/52 [==============================] - 39s 742ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 4.3828 - val_accuracy: 0.5737\n",
      "Epoch 117/200\n",
      "52/52 [==============================] - 38s 732ms/step - loss: 0.0495 - accuracy: 0.9907 - val_loss: 4.3031 - val_accuracy: 0.5755\n",
      "Epoch 118/200\n",
      "52/52 [==============================] - 39s 743ms/step - loss: 0.0272 - accuracy: 0.9940 - val_loss: 4.3770 - val_accuracy: 0.5815\n",
      "Epoch 119/200\n",
      "52/52 [==============================] - 39s 753ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 4.3636 - val_accuracy: 0.5839\n",
      "Epoch 120/200\n",
      "35/52 [===================>..........] - ETA: 11s - loss: 0.0122 - accuracy: 0.9970"
     ]
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "transformer.summary()\n",
    "historial = transformer.fit(dataset_train, epochs = 200, validation_data = dataset_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8c7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:00:48.798733Z",
     "iopub.status.busy": "2023-03-19T19:00:48.798292Z",
     "iopub.status.idle": "2023-03-19T19:01:02.344011Z",
     "shell.execute_reply": "2023-03-19T19:01:02.343089Z"
    },
    "papermill": {
     "duration": 14.228796,
     "end_time": "2023-03-19T19:01:02.347498",
     "exception": false,
     "start_time": "2023-03-19T19:00:48.118702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "transformer.save('output/model_spanish_kichwa')\n",
    "\n",
    "# save the pares train to use on the server\n",
    "with open('output/pares_spanish_kichwa.txt', 'w') as f:\n",
    "    for par in pares_train:\n",
    "        par_string = ''.join(par)\n",
    "        f.write(par_string)\n",
    "        f.write('\\n')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d392b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:01:03.795429Z",
     "iopub.status.busy": "2023-03-19T19:01:03.794700Z",
     "iopub.status.idle": "2023-03-19T19:01:04.084503Z",
     "shell.execute_reply": "2023-03-19T19:01:04.083133Z"
    },
    "papermill": {
     "duration": 0.976011,
     "end_time": "2023-03-19T19:01:04.086839",
     "exception": false,
     "start_time": "2023-03-19T19:01:03.110828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('perdida')\n",
    "plt.plot(historial.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ac073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:01:05.511549Z",
     "iopub.status.busy": "2023-03-19T19:01:05.510578Z",
     "iopub.status.idle": "2023-03-19T19:01:07.361279Z",
     "shell.execute_reply": "2023-03-19T19:01:07.360493Z"
    },
    "papermill": {
     "duration": 2.601532,
     "end_time": "2023-03-19T19:01:07.364634",
     "exception": false,
     "start_time": "2023-03-19T19:01:04.763102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_kichwa = texto_target_vectorizado.get_vocabulary()\n",
    "busqueda_kichwa = dict(zip(range(len(vocab_kichwa)), vocab_kichwa))\n",
    "max_len_sentence = 7\n",
    "\n",
    "\n",
    "def traducir(input_sentence):\n",
    "    tokenized_input_sentence = texto_source_vectorizado([input_sentence])\n",
    "    sentence_decoded = \"[start]\"\n",
    "    for i in range(max_len_sentence):\n",
    "        sentence_target_tokenized = texto_target_vectorizado(\n",
    "            [sentence_decoded])[:, :-1]\n",
    "        predicciones = transformer(\n",
    "            [tokenized_input_sentence, sentence_target_tokenized])\n",
    "        index_token = np.argmax(predicciones[0, i, :])\n",
    "        token = busqueda_kichwa[index_token]\n",
    "        sentence_decoded += \" \" + token\n",
    "        if token == \"[end]\":\n",
    "            break\n",
    "    return sentence_decoded\n",
    "\n",
    "test_spanish_texts = [pair[0] for pair in pares_train]\n",
    "\n",
    "for _ in range(10):\n",
    "    input_sentence = random.choice(test_spanish_texts)\n",
    "    print(input_sentence)\n",
    "    print(traducir(input_sentence))\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8c81f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:01:08.826525Z",
     "iopub.status.busy": "2023-03-19T19:01:08.825318Z",
     "iopub.status.idle": "2023-03-19T19:01:08.933076Z",
     "shell.execute_reply": "2023-03-19T19:01:08.931766Z"
    },
    "papermill": {
     "duration": 0.871847,
     "end_time": "2023-03-19T19:01:08.935909",
     "exception": false,
     "start_time": "2023-03-19T19:01:08.064062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(traducir(\"hola\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4082.746343,
   "end_time": "2023-03-19T19:01:13.021109",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-19T17:53:10.274766",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f650c42177d71d9d442d1237f6fd42533fcf5dfc49185c5979f4d948a86906b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
