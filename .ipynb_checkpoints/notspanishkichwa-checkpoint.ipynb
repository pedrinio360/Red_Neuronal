{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a82ad5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:20.162782Z",
     "iopub.status.busy": "2023-03-19T17:53:20.162277Z",
     "iopub.status.idle": "2023-03-19T17:53:30.199736Z",
     "shell.execute_reply": "2023-03-19T17:53:30.198436Z"
    },
    "papermill": {
     "duration": 10.05235,
     "end_time": "2023-03-19T17:53:30.203159",
     "exception": false,
     "start_time": "2023-03-19T17:53:20.150809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 11:33:11.064382: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce97b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.216258Z",
     "iopub.status.busy": "2023-03-19T17:53:30.214571Z",
     "iopub.status.idle": "2023-03-19T17:53:30.246329Z",
     "shell.execute_reply": "2023-03-19T17:53:30.245072Z"
    },
    "papermill": {
     "duration": 0.040737,
     "end_time": "2023-03-19T17:53:30.249132",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.208395",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding = 'utf8') as f:\n",
    "        data = f.read()\n",
    "    return data.split('\\n')\n",
    "\n",
    "spanish_sentences = load_data('data/input/spanish_vocab.txt')\n",
    "kichwa_sentences = load_data('data/input/kichwa_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edf6fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.261003Z",
     "iopub.status.busy": "2023-03-19T17:53:30.260206Z",
     "iopub.status.idle": "2023-03-19T17:53:30.269237Z",
     "shell.execute_reply": "2023-03-19T17:53:30.268173Z"
    },
    "papermill": {
     "duration": 0.017824,
     "end_time": "2023-03-19T17:53:30.271820",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.253996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pares_oraciones = []\n",
    "for index, item in enumerate(spanish_sentences, start=0):\n",
    "    spanish = item\n",
    "    kichwa = \"[start] \" + kichwa_sentences[index] + \" [end]\"\n",
    "    pares_oraciones.append((spanish, kichwa))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0097c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.283302Z",
     "iopub.status.busy": "2023-03-19T17:53:30.282506Z",
     "iopub.status.idle": "2023-03-19T17:53:30.292821Z",
     "shell.execute_reply": "2023-03-19T17:53:30.291523Z"
    },
    "papermill": {
     "duration": 0.018476,
     "end_time": "2023-03-19T17:53:30.294975",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.276499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.shuffle(pares_oraciones)\n",
    "num_pares_validar = int(0.1 * len(pares_oraciones))\n",
    "num_pares_train = int(0.9 * len(pares_oraciones))\n",
    "pares_train = pares_oraciones[:num_pares_train]\n",
    "pares_validar = pares_oraciones[num_pares_train:num_pares_train + num_pares_validar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959937f5",
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:30.306012Z",
     "iopub.status.busy": "2023-03-19T17:53:30.305616Z",
     "iopub.status.idle": "2023-03-19T17:53:31.060996Z",
     "shell.execute_reply": "2023-03-19T17:53:31.058941Z"
    },
    "papermill": {
     "duration": 0.766845,
     "end_time": "2023-03-19T17:53:31.066488",
     "exception": false,
     "start_time": "2023-03-19T17:53:30.299643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 11:33:17.430989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "modificar_chars = string.punctuation + \"Â¿\"\n",
    "modificar_chars = modificar_chars.replace(\"[\", \"\")\n",
    "modificar_chars = modificar_chars.replace(\"]\", \"\")\n",
    "\n",
    "len_sentences = 7\n",
    "num_vocab = 5000\n",
    "\n",
    "def get_standardization(text):\n",
    "    texto = tf.strings.lower(text)\n",
    "    return tf.strings.regex_replace(\n",
    "        texto, f\"[{re.escape(modificar_chars)}]\", \"\")\n",
    "\n",
    "texto_source_vectorizado = layers.TextVectorization(\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = len_sentences,\n",
    "    max_tokens = num_vocab,\n",
    "    standardize = get_standardization\n",
    ")\n",
    "texto_target_vectorizado = layers.TextVectorization(\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = len_sentences + 1,\n",
    "    max_tokens = num_vocab,\n",
    "    standardize = get_standardization\n",
    ")\n",
    "\n",
    "textos_train_spanish = [par[0] for par in pares_train]\n",
    "textos_train_kichwa = [par[1] for par in pares_train]\n",
    "texto_source_vectorizado.adapt(textos_train_spanish)\n",
    "texto_target_vectorizado.adapt(textos_train_kichwa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64723905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.082835Z",
     "iopub.status.busy": "2023-03-19T17:53:31.082011Z",
     "iopub.status.idle": "2023-03-19T17:53:31.628318Z",
     "shell.execute_reply": "2023-03-19T17:53:31.626766Z"
    },
    "papermill": {
     "duration": 0.558046,
     "end_time": "2023-03-19T17:53:31.630941",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.072895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entradas['spanish'].shape: (64, 7)\n",
      "entradas['kichwa'].shape: (64, 7)\n",
      "salidas.shape: (64, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 11:33:18.172910: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def set_format(spanish, kichwa):\n",
    "    spanish = texto_source_vectorizado(spanish) \n",
    "    kichwa = texto_target_vectorizado(kichwa)\n",
    "    return (\n",
    "        {\n",
    "            \"spanish\": spanish,\n",
    "            \"kichwa\": kichwa[:, :-1],\n",
    "        }, \n",
    "        kichwa[:, 1:]\n",
    "    )\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    textos_spanish, textos_kichwa = zip(*pairs)\n",
    "    textos_spanish = list(textos_spanish)\n",
    "    textos_kichwa = list(textos_kichwa)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((textos_spanish, textos_kichwa))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(set_format, num_parallel_calls=4)\n",
    "\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "dataset_train = make_dataset(pares_train)\n",
    "dataset_validacion = make_dataset(pares_validar)\n",
    "\n",
    "for entradas, salidas in dataset_train.take(1):\n",
    "    print(f\"entradas['spanish'].shape: {entradas['spanish'].shape}\")\n",
    "    print(f\"entradas['kichwa'].shape: {entradas['kichwa'].shape}\")\n",
    "    print(f\"salidas.shape: {salidas.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254156a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.643641Z",
     "iopub.status.busy": "2023-03-19T17:53:31.642675Z",
     "iopub.status.idle": "2023-03-19T17:53:31.653628Z",
     "shell.execute_reply": "2023-03-19T17:53:31.652257Z"
    },
    "papermill": {
     "duration": 0.020517,
     "end_time": "2023-03-19T17:53:31.656489",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.635972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderTrans(layers.Layer):\n",
    "\n",
    "    def __init__(self, num_heads, dense_dim, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.dense_dim = dense_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attention = layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(\n",
    "                dense_dim, \n",
    "                activation = \"relu\"\n",
    "            ),\n",
    "            layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, entradas, mask = None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_salida = self.attention(entradas, entradas, attention_mask = mask)\n",
    "        proj_entrada = self.layernorm_1(entradas + attention_salida)\n",
    "        proj_salida = self.dense_proj(proj_entrada)\n",
    "\n",
    "        return self.layernorm_2(proj_entrada + proj_salida)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a79e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.667833Z",
     "iopub.status.busy": "2023-03-19T17:53:31.667387Z",
     "iopub.status.idle": "2023-03-19T17:53:31.683582Z",
     "shell.execute_reply": "2023-03-19T17:53:31.682641Z"
    },
    "papermill": {
     "duration": 0.024937,
     "end_time": "2023-03-19T17:53:31.686249",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.661312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderTrans(layers.Layer):\n",
    "    def __init__(self, num_heads, dense_dim, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.dense_dim = dense_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation = \"relu\"),\n",
    "             layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_mask_attention_causal(self, entradas):\n",
    "        shape_entrada = tf.shape(entradas)\n",
    "        batch_size, len_sequence = shape_entrada[0], shape_entrada[1]\n",
    "        i = tf.range(len_sequence)[:, tf.newaxis]\n",
    "        j = tf.range(len_sequence)\n",
    "        mask = tf.cast(i >= j, dtype = \"int32\")\n",
    "        mask = tf.reshape(mask, (1, shape_entrada[1], shape_entrada[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype = tf.int32)], axis = 0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, entradas, salidas_encoder, mask = None):\n",
    "        mask_causal = self.get_mask_attention_causal(entradas)\n",
    "        if mask is not None:\n",
    "            mask_padding = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            mask_padding = tf.minimum(mask_padding, mask_causal)\n",
    "        attention_salida_1 = self.attention_1(\n",
    "            query = entradas,\n",
    "            value = entradas,\n",
    "            key = entradas,\n",
    "            attention_mask = mask_causal)\n",
    "        attention_salida_1 = self.layernorm_1(entradas + attention_salida_1)\n",
    "        attention_salida_2 = self.attention_2(\n",
    "            query = attention_salida_1,\n",
    "            value = salidas_encoder,\n",
    "            key = salidas_encoder,\n",
    "            attention_mask = mask_padding,\n",
    "        )\n",
    "        attention_salida_2 = self.layernorm_2(\n",
    "            attention_salida_1 + attention_salida_2)\n",
    "        proj_salida = self.dense_proj(attention_salida_2)\n",
    "\n",
    "        return self.layernorm_3(attention_salida_2 + proj_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c9a967a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.697314Z",
     "iopub.status.busy": "2023-03-19T17:53:31.696910Z",
     "iopub.status.idle": "2023-03-19T17:53:31.706902Z",
     "shell.execute_reply": "2023-03-19T17:53:31.705659Z"
    },
    "papermill": {
     "duration": 0.018087,
     "end_time": "2023-03-19T17:53:31.709032",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.690945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "\n",
    "    def __init__(self, dim_entrada, dim_salida, len_sentences, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_dim = dim_entrada\n",
    "        self.output_dim = dim_salida\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim = dim_entrada, output_dim = dim_salida)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim = len_sentences, output_dim = dim_salida)\n",
    "        self.sequence_length = len_sentences\n",
    "\n",
    "    def call(self, entradas):\n",
    "        limite = tf.shape(entradas)[-1]\n",
    "        posiciones = tf.range(start = 0, limit = limite, delta = 1)\n",
    "        tokens_embedded = self.token_embeddings(entradas)\n",
    "        posiciones_embedded = self.position_embeddings(posiciones)\n",
    "        return tokens_embedded + posiciones_embedded\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ed0383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:31.720389Z",
     "iopub.status.busy": "2023-03-19T17:53:31.719425Z",
     "iopub.status.idle": "2023-03-19T17:53:32.750217Z",
     "shell.execute_reply": "2023-03-19T17:53:32.748923Z"
    },
    "papermill": {
     "duration": 1.039676,
     "end_time": "2023-03-19T17:53:32.753394",
     "exception": false,
     "start_time": "2023-03-19T17:53:31.713718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "\n",
    "entradas_encoder = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEncoding(num_vocab, embed_dim, len_sentences)(entradas_encoder)\n",
    "salidas_encoder = EncoderTrans(num_heads, dense_dim, embed_dim )(x)\n",
    "\n",
    "entradas_decoder = keras.Input(shape=(None,), dtype=\"int64\", name=\"kichwa\")\n",
    "x = PositionalEncoding(num_vocab, embed_dim, len_sentences,)(entradas_decoder)\n",
    "x = DecoderTrans(num_heads, dense_dim, embed_dim )(x, salidas_encoder)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "salidas_decoder = layers.Dense(num_vocab, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([entradas_encoder, entradas_decoder], salidas_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b746ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T17:53:32.765559Z",
     "iopub.status.busy": "2023-03-19T17:53:32.764327Z",
     "iopub.status.idle": "2023-03-19T19:00:47.433546Z",
     "shell.execute_reply": "2023-03-19T19:00:47.431963Z"
    },
    "papermill": {
     "duration": 4034.678285,
     "end_time": "2023-03-19T19:00:47.436499",
     "exception": false,
     "start_time": "2023-03-19T17:53:32.758214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "52/52 [==============================] - 23s 374ms/step - loss: 3.2835 - accuracy: 0.4003 - val_loss: 3.1997 - val_accuracy: 0.3899\n",
      "Epoch 2/200\n",
      "52/52 [==============================] - 18s 354ms/step - loss: 2.7424 - accuracy: 0.4514 - val_loss: 3.1219 - val_accuracy: 0.3941\n",
      "Epoch 3/200\n",
      "52/52 [==============================] - 22s 418ms/step - loss: 2.6151 - accuracy: 0.4547 - val_loss: 2.9795 - val_accuracy: 0.4534\n",
      "Epoch 4/200\n",
      "52/52 [==============================] - 22s 421ms/step - loss: 2.5135 - accuracy: 0.4632 - val_loss: 2.9735 - val_accuracy: 0.4534\n",
      "Epoch 5/200\n",
      "52/52 [==============================] - 32s 603ms/step - loss: 2.4603 - accuracy: 0.4688 - val_loss: 2.9160 - val_accuracy: 0.4540\n",
      "Epoch 6/200\n",
      "52/52 [==============================] - 30s 575ms/step - loss: 2.3960 - accuracy: 0.4737 - val_loss: 2.8874 - val_accuracy: 0.4558\n",
      "Epoch 7/200\n",
      "52/52 [==============================] - 41s 786ms/step - loss: 2.3451 - accuracy: 0.4794 - val_loss: 2.8650 - val_accuracy: 0.4463\n",
      "Epoch 8/200\n",
      "52/52 [==============================] - 30s 572ms/step - loss: 2.2943 - accuracy: 0.4796 - val_loss: 2.8908 - val_accuracy: 0.4558\n",
      "Epoch 9/200\n",
      "52/52 [==============================] - 17s 330ms/step - loss: 2.2465 - accuracy: 0.4873 - val_loss: 2.9638 - val_accuracy: 0.4398\n",
      "Epoch 10/200\n",
      "52/52 [==============================] - 17s 330ms/step - loss: 2.2037 - accuracy: 0.4876 - val_loss: 2.9690 - val_accuracy: 0.4516\n",
      "Epoch 11/200\n",
      "52/52 [==============================] - 17s 334ms/step - loss: 2.1631 - accuracy: 0.4931 - val_loss: 3.0213 - val_accuracy: 0.4332\n",
      "Epoch 12/200\n",
      "52/52 [==============================] - 17s 332ms/step - loss: 2.1291 - accuracy: 0.4970 - val_loss: 2.9697 - val_accuracy: 0.4540\n",
      "Epoch 13/200\n",
      "52/52 [==============================] - 17s 332ms/step - loss: 2.0979 - accuracy: 0.5024 - val_loss: 3.0236 - val_accuracy: 0.4665\n",
      "Epoch 14/200\n",
      "52/52 [==============================] - 17s 332ms/step - loss: 2.0361 - accuracy: 0.5059 - val_loss: 2.9225 - val_accuracy: 0.4629\n",
      "Epoch 15/200\n",
      "52/52 [==============================] - 17s 334ms/step - loss: 1.9926 - accuracy: 0.5099 - val_loss: 2.9310 - val_accuracy: 0.4706\n",
      "Epoch 16/200\n",
      "52/52 [==============================] - 23s 440ms/step - loss: 1.9439 - accuracy: 0.5194 - val_loss: 2.9754 - val_accuracy: 0.4463\n",
      "Epoch 17/200\n",
      "52/52 [==============================] - 5468s 107s/step - loss: 1.8908 - accuracy: 0.5266 - val_loss: 3.0515 - val_accuracy: 0.4629\n",
      "Epoch 18/200\n",
      "52/52 [==============================] - 7919s 155s/step - loss: 1.8432 - accuracy: 0.5382 - val_loss: 2.9841 - val_accuracy: 0.4653\n",
      "Epoch 19/200\n",
      "52/52 [==============================] - 27s 510ms/step - loss: 1.7957 - accuracy: 0.5444 - val_loss: 2.9937 - val_accuracy: 0.4504\n",
      "Epoch 20/200\n",
      "52/52 [==============================] - 24s 450ms/step - loss: 1.7276 - accuracy: 0.5623 - val_loss: 2.9815 - val_accuracy: 0.4700\n",
      "Epoch 21/200\n",
      "52/52 [==============================] - 21s 397ms/step - loss: 1.6759 - accuracy: 0.5742 - val_loss: 2.9431 - val_accuracy: 0.4682\n",
      "Epoch 22/200\n",
      "52/52 [==============================] - 23s 443ms/step - loss: 1.6090 - accuracy: 0.5931 - val_loss: 2.9439 - val_accuracy: 0.4700\n",
      "Epoch 23/200\n",
      "52/52 [==============================] - 22s 428ms/step - loss: 1.5466 - accuracy: 0.6090 - val_loss: 2.9521 - val_accuracy: 0.4783\n",
      "Epoch 24/200\n",
      "52/52 [==============================] - 17s 334ms/step - loss: 1.4898 - accuracy: 0.6261 - val_loss: 3.1522 - val_accuracy: 0.4546\n",
      "Epoch 25/200\n",
      "52/52 [==============================] - 17s 321ms/step - loss: 1.4369 - accuracy: 0.6376 - val_loss: 2.9198 - val_accuracy: 0.4813\n",
      "Epoch 26/200\n",
      "52/52 [==============================] - 18s 338ms/step - loss: 1.3735 - accuracy: 0.6534 - val_loss: 2.9000 - val_accuracy: 0.4843\n",
      "Epoch 27/200\n",
      "52/52 [==============================] - 17s 325ms/step - loss: 1.3159 - accuracy: 0.6693 - val_loss: 3.0142 - val_accuracy: 0.4783\n",
      "Epoch 28/200\n",
      "52/52 [==============================] - 17s 329ms/step - loss: 1.2773 - accuracy: 0.6812 - val_loss: 2.9634 - val_accuracy: 0.4825\n",
      "Epoch 29/200\n",
      "52/52 [==============================] - 17s 330ms/step - loss: 1.2331 - accuracy: 0.6928 - val_loss: 2.9096 - val_accuracy: 0.4955\n",
      "Epoch 30/200\n",
      "52/52 [==============================] - 17s 320ms/step - loss: 1.1811 - accuracy: 0.7035 - val_loss: 3.0111 - val_accuracy: 0.4807\n",
      "Epoch 31/200\n",
      "52/52 [==============================] - 17s 327ms/step - loss: 1.1452 - accuracy: 0.7111 - val_loss: 3.0402 - val_accuracy: 0.4540\n",
      "Epoch 32/200\n",
      "52/52 [==============================] - 17s 325ms/step - loss: 1.1075 - accuracy: 0.7206 - val_loss: 2.9640 - val_accuracy: 0.4938\n",
      "Epoch 33/200\n",
      "52/52 [==============================] - 17s 324ms/step - loss: 1.0775 - accuracy: 0.7303 - val_loss: 2.9194 - val_accuracy: 0.4884\n",
      "Epoch 34/200\n",
      "52/52 [==============================] - 17s 329ms/step - loss: 1.0514 - accuracy: 0.7338 - val_loss: 2.9454 - val_accuracy: 0.4819\n",
      "Epoch 35/200\n",
      "52/52 [==============================] - 17s 318ms/step - loss: 1.0262 - accuracy: 0.7401 - val_loss: 2.9516 - val_accuracy: 0.4890\n",
      "Epoch 36/200\n",
      "52/52 [==============================] - 17s 324ms/step - loss: 1.0017 - accuracy: 0.7468 - val_loss: 2.9186 - val_accuracy: 0.4908\n",
      "Epoch 37/200\n",
      "52/52 [==============================] - 17s 324ms/step - loss: 0.9853 - accuracy: 0.7488 - val_loss: 2.9368 - val_accuracy: 0.4866\n",
      "Epoch 38/200\n",
      "52/52 [==============================] - 17s 324ms/step - loss: 0.9662 - accuracy: 0.7545 - val_loss: 2.9321 - val_accuracy: 0.4979\n",
      "Epoch 39/200\n",
      "52/52 [==============================] - 17s 333ms/step - loss: 0.9474 - accuracy: 0.7624 - val_loss: 2.9380 - val_accuracy: 0.4950\n",
      "Epoch 40/200\n",
      "52/52 [==============================] - 17s 319ms/step - loss: 0.9342 - accuracy: 0.7644 - val_loss: 2.9466 - val_accuracy: 0.4920\n",
      "Epoch 41/200\n",
      "52/52 [==============================] - 18s 341ms/step - loss: 0.9173 - accuracy: 0.7719 - val_loss: 2.9859 - val_accuracy: 0.4807\n",
      "Epoch 42/200\n",
      "52/52 [==============================] - 17s 326ms/step - loss: 0.9133 - accuracy: 0.7707 - val_loss: 2.9240 - val_accuracy: 0.4955\n",
      "Epoch 43/200\n",
      "52/52 [==============================] - 17s 331ms/step - loss: 0.8917 - accuracy: 0.7772 - val_loss: 3.0854 - val_accuracy: 0.4546\n",
      "Epoch 44/200\n",
      "52/52 [==============================] - 17s 328ms/step - loss: 0.8730 - accuracy: 0.7834 - val_loss: 3.0124 - val_accuracy: 0.4718\n",
      "Epoch 45/200\n",
      "52/52 [==============================] - 17s 328ms/step - loss: 0.8719 - accuracy: 0.7863 - val_loss: 2.9839 - val_accuracy: 0.4908\n",
      "Epoch 46/200\n",
      "52/52 [==============================] - 17s 328ms/step - loss: 0.8548 - accuracy: 0.7876 - val_loss: 2.9762 - val_accuracy: 0.4783\n",
      "Epoch 47/200\n",
      "52/52 [==============================] - 17s 328ms/step - loss: 0.8488 - accuracy: 0.7909 - val_loss: 2.9468 - val_accuracy: 0.4926\n",
      "Epoch 48/200\n",
      "52/52 [==============================] - 17s 328ms/step - loss: 0.8426 - accuracy: 0.7906 - val_loss: 2.9508 - val_accuracy: 0.4997\n",
      "Epoch 49/200\n",
      "52/52 [==============================] - 17s 328ms/step - loss: 0.8309 - accuracy: 0.7935 - val_loss: 2.9772 - val_accuracy: 0.4861\n",
      "Epoch 50/200\n",
      "52/52 [==============================] - 17s 329ms/step - loss: 0.8244 - accuracy: 0.7992 - val_loss: 2.9949 - val_accuracy: 0.4855\n",
      "Epoch 51/200\n",
      "52/52 [==============================] - 17s 337ms/step - loss: 0.8172 - accuracy: 0.7996 - val_loss: 2.9816 - val_accuracy: 0.4855\n",
      "Epoch 52/200\n",
      "52/52 [==============================] - 17s 329ms/step - loss: 0.8097 - accuracy: 0.8014 - val_loss: 2.9682 - val_accuracy: 0.4920\n",
      "Epoch 53/200\n",
      "52/52 [==============================] - 18s 343ms/step - loss: 0.8071 - accuracy: 0.7996 - val_loss: 2.9960 - val_accuracy: 0.4861\n",
      "Epoch 54/200\n",
      "52/52 [==============================] - 18s 351ms/step - loss: 0.7937 - accuracy: 0.8065 - val_loss: 2.9573 - val_accuracy: 0.5021\n",
      "Epoch 55/200\n",
      "52/52 [==============================] - 19s 373ms/step - loss: 0.7882 - accuracy: 0.8084 - val_loss: 2.9797 - val_accuracy: 0.4979\n",
      "Epoch 56/200\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.7701 - accuracy: 0.8147 - val_loss: 3.0290 - val_accuracy: 0.4866\n",
      "Epoch 57/200\n",
      "52/52 [==============================] - 18s 344ms/step - loss: 0.7735 - accuracy: 0.8134 - val_loss: 3.0046 - val_accuracy: 0.4967\n",
      "Epoch 58/200\n",
      "52/52 [==============================] - 23s 450ms/step - loss: 0.7640 - accuracy: 0.8132 - val_loss: 2.9890 - val_accuracy: 0.5080\n",
      "Epoch 59/200\n",
      "52/52 [==============================] - 26s 511ms/step - loss: 0.7532 - accuracy: 0.8174 - val_loss: 3.2829 - val_accuracy: 0.4255\n",
      "Epoch 60/200\n",
      "52/52 [==============================] - 28s 533ms/step - loss: 0.7475 - accuracy: 0.8222 - val_loss: 3.0009 - val_accuracy: 0.5086\n",
      "Epoch 61/200\n",
      "52/52 [==============================] - 25s 480ms/step - loss: 0.7334 - accuracy: 0.8242 - val_loss: 2.9872 - val_accuracy: 0.5074\n",
      "Epoch 62/200\n",
      "52/52 [==============================] - 19s 361ms/step - loss: 0.7275 - accuracy: 0.8263 - val_loss: 3.0062 - val_accuracy: 0.5003\n",
      "Epoch 63/200\n",
      "52/52 [==============================] - 23s 433ms/step - loss: 0.7211 - accuracy: 0.8323 - val_loss: 3.0176 - val_accuracy: 0.4950\n",
      "Epoch 64/200\n",
      "52/52 [==============================] - 27s 522ms/step - loss: 0.7105 - accuracy: 0.8338 - val_loss: 3.0149 - val_accuracy: 0.4944\n",
      "Epoch 65/200\n",
      "52/52 [==============================] - 24s 467ms/step - loss: 0.7110 - accuracy: 0.8317 - val_loss: 3.0118 - val_accuracy: 0.5003\n",
      "Epoch 66/200\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 0.6906 - accuracy: 0.8376 - val_loss: 3.0403 - val_accuracy: 0.5021\n",
      "Epoch 67/200\n",
      "52/52 [==============================] - 24s 457ms/step - loss: 0.6884 - accuracy: 0.8399 - val_loss: 3.0446 - val_accuracy: 0.4997\n",
      "Epoch 68/200\n",
      "52/52 [==============================] - 26s 499ms/step - loss: 0.6785 - accuracy: 0.8432 - val_loss: 3.0750 - val_accuracy: 0.4843\n",
      "Epoch 69/200\n",
      "52/52 [==============================] - 31s 607ms/step - loss: 0.6819 - accuracy: 0.8427 - val_loss: 3.0170 - val_accuracy: 0.5021\n",
      "Epoch 70/200\n",
      "52/52 [==============================] - 26s 502ms/step - loss: 0.6665 - accuracy: 0.8470 - val_loss: 3.1007 - val_accuracy: 0.4831\n",
      "Epoch 71/200\n",
      "52/52 [==============================] - 21s 407ms/step - loss: 0.6563 - accuracy: 0.8485 - val_loss: 3.0729 - val_accuracy: 0.5021\n",
      "Epoch 72/200\n",
      "52/52 [==============================] - 21s 401ms/step - loss: 0.6514 - accuracy: 0.8537 - val_loss: 3.0507 - val_accuracy: 0.5009\n",
      "Epoch 73/200\n",
      "52/52 [==============================] - 21s 412ms/step - loss: 0.6338 - accuracy: 0.8585 - val_loss: 3.0449 - val_accuracy: 0.5110\n",
      "Epoch 74/200\n",
      "52/52 [==============================] - 24s 459ms/step - loss: 0.6378 - accuracy: 0.8577 - val_loss: 3.0368 - val_accuracy: 0.5021\n",
      "Epoch 75/200\n",
      "52/52 [==============================] - 27s 521ms/step - loss: 0.6308 - accuracy: 0.8579 - val_loss: 3.0456 - val_accuracy: 0.5092\n",
      "Epoch 76/200\n",
      "52/52 [==============================] - 22s 429ms/step - loss: 0.6251 - accuracy: 0.8615 - val_loss: 3.0574 - val_accuracy: 0.5074\n",
      "Epoch 77/200\n",
      "52/52 [==============================] - 20s 380ms/step - loss: 0.6215 - accuracy: 0.8637 - val_loss: 3.0742 - val_accuracy: 0.4890\n",
      "Epoch 78/200\n",
      "52/52 [==============================] - 22s 415ms/step - loss: 0.6109 - accuracy: 0.8674 - val_loss: 3.0963 - val_accuracy: 0.4955\n",
      "Epoch 79/200\n",
      "52/52 [==============================] - 21s 398ms/step - loss: 0.6069 - accuracy: 0.8694 - val_loss: 3.0662 - val_accuracy: 0.5080\n",
      "Epoch 80/200\n",
      "52/52 [==============================] - 20s 395ms/step - loss: 0.6002 - accuracy: 0.8716 - val_loss: 3.0863 - val_accuracy: 0.5033\n",
      "Epoch 81/200\n",
      "52/52 [==============================] - 21s 401ms/step - loss: 0.5929 - accuracy: 0.8743 - val_loss: 3.0908 - val_accuracy: 0.5086\n",
      "Epoch 82/200\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.5898 - accuracy: 0.8736 - val_loss: 3.0618 - val_accuracy: 0.5050\n",
      "Epoch 83/200\n",
      "52/52 [==============================] - 19s 367ms/step - loss: 0.5828 - accuracy: 0.8763 - val_loss: 3.0763 - val_accuracy: 0.5068\n",
      "Epoch 84/200\n",
      "52/52 [==============================] - 21s 395ms/step - loss: 0.5733 - accuracy: 0.8802 - val_loss: 3.0438 - val_accuracy: 0.5116\n",
      "Epoch 85/200\n",
      "52/52 [==============================] - 19s 368ms/step - loss: 0.5703 - accuracy: 0.8795 - val_loss: 3.1118 - val_accuracy: 0.5092\n",
      "Epoch 86/200\n",
      "52/52 [==============================] - 20s 378ms/step - loss: 0.5597 - accuracy: 0.8837 - val_loss: 3.0856 - val_accuracy: 0.5015\n",
      "Epoch 87/200\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 0.5588 - accuracy: 0.8857 - val_loss: 3.1148 - val_accuracy: 0.4973\n",
      "Epoch 88/200\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.5532 - accuracy: 0.8849 - val_loss: 3.0994 - val_accuracy: 0.5122\n",
      "Epoch 89/200\n",
      "52/52 [==============================] - 21s 406ms/step - loss: 0.5529 - accuracy: 0.8845 - val_loss: 3.1812 - val_accuracy: 0.4861\n",
      "Epoch 90/200\n",
      "52/52 [==============================] - 20s 376ms/step - loss: 0.5358 - accuracy: 0.8930 - val_loss: 3.1242 - val_accuracy: 0.5074\n",
      "Epoch 91/200\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.5422 - accuracy: 0.8880 - val_loss: 3.1419 - val_accuracy: 0.4979\n",
      "Epoch 92/200\n",
      "52/52 [==============================] - 19s 364ms/step - loss: 0.5341 - accuracy: 0.8918 - val_loss: 3.1428 - val_accuracy: 0.4955\n",
      "Epoch 93/200\n",
      "52/52 [==============================] - 19s 368ms/step - loss: 0.5314 - accuracy: 0.8939 - val_loss: 3.1315 - val_accuracy: 0.5050\n",
      "Epoch 94/200\n",
      "52/52 [==============================] - 19s 364ms/step - loss: 0.5274 - accuracy: 0.8946 - val_loss: 3.1413 - val_accuracy: 0.4955\n",
      "Epoch 95/200\n",
      "52/52 [==============================] - 21s 402ms/step - loss: 0.5175 - accuracy: 0.8986 - val_loss: 3.1605 - val_accuracy: 0.5128\n",
      "Epoch 96/200\n",
      "52/52 [==============================] - 20s 390ms/step - loss: 0.5184 - accuracy: 0.8990 - val_loss: 3.1729 - val_accuracy: 0.5021\n",
      "Epoch 97/200\n",
      "52/52 [==============================] - 26s 496ms/step - loss: 0.5095 - accuracy: 0.9014 - val_loss: 3.2123 - val_accuracy: 0.4861\n",
      "Epoch 98/200\n",
      "52/52 [==============================] - 20s 380ms/step - loss: 0.5154 - accuracy: 0.8983 - val_loss: 3.1526 - val_accuracy: 0.5086\n",
      "Epoch 99/200\n",
      "52/52 [==============================] - 20s 390ms/step - loss: 0.4981 - accuracy: 0.9044 - val_loss: 3.1623 - val_accuracy: 0.5104\n",
      "Epoch 100/200\n",
      "52/52 [==============================] - 20s 380ms/step - loss: 0.5019 - accuracy: 0.9040 - val_loss: 3.1650 - val_accuracy: 0.5086\n",
      "Epoch 101/200\n",
      "52/52 [==============================] - 19s 355ms/step - loss: 0.4922 - accuracy: 0.9052 - val_loss: 3.1640 - val_accuracy: 0.5062\n",
      "Epoch 102/200\n",
      "52/52 [==============================] - 19s 367ms/step - loss: 0.4918 - accuracy: 0.9050 - val_loss: 3.1801 - val_accuracy: 0.5086\n",
      "Epoch 103/200\n",
      "52/52 [==============================] - 20s 386ms/step - loss: 0.4861 - accuracy: 0.9074 - val_loss: 3.1853 - val_accuracy: 0.5128\n",
      "Epoch 104/200\n",
      "52/52 [==============================] - 22s 427ms/step - loss: 0.4863 - accuracy: 0.9077 - val_loss: 3.1567 - val_accuracy: 0.5098\n",
      "Epoch 105/200\n",
      "52/52 [==============================] - 23s 436ms/step - loss: 0.4815 - accuracy: 0.9093 - val_loss: 3.1658 - val_accuracy: 0.5080\n",
      "Epoch 106/200\n",
      "52/52 [==============================] - 21s 407ms/step - loss: 0.4737 - accuracy: 0.9112 - val_loss: 3.2021 - val_accuracy: 0.5039\n",
      "Epoch 107/200\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.4813 - accuracy: 0.9091 - val_loss: 3.1720 - val_accuracy: 0.5110\n",
      "Epoch 108/200\n",
      "52/52 [==============================] - 20s 390ms/step - loss: 0.4636 - accuracy: 0.9148 - val_loss: 3.2133 - val_accuracy: 0.5050\n",
      "Epoch 109/200\n",
      "52/52 [==============================] - 21s 398ms/step - loss: 0.4658 - accuracy: 0.9131 - val_loss: 3.2127 - val_accuracy: 0.5104\n",
      "Epoch 110/200\n",
      "52/52 [==============================] - 21s 397ms/step - loss: 0.4677 - accuracy: 0.9137 - val_loss: 3.2127 - val_accuracy: 0.5068\n",
      "Epoch 111/200\n",
      "52/52 [==============================] - 20s 378ms/step - loss: 0.4594 - accuracy: 0.9168 - val_loss: 3.1962 - val_accuracy: 0.5128\n",
      "Epoch 112/200\n",
      "52/52 [==============================] - 20s 383ms/step - loss: 0.4550 - accuracy: 0.9186 - val_loss: 3.1969 - val_accuracy: 0.5098\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 20s 389ms/step - loss: 0.4498 - accuracy: 0.9187 - val_loss: 3.2409 - val_accuracy: 0.5122\n",
      "Epoch 114/200\n",
      "52/52 [==============================] - 19s 364ms/step - loss: 0.4449 - accuracy: 0.9192 - val_loss: 3.2099 - val_accuracy: 0.5092\n",
      "Epoch 115/200\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.4500 - accuracy: 0.9209 - val_loss: 3.2159 - val_accuracy: 0.5128\n",
      "Epoch 116/200\n",
      "52/52 [==============================] - 19s 375ms/step - loss: 0.4421 - accuracy: 0.9224 - val_loss: 3.2249 - val_accuracy: 0.5122\n",
      "Epoch 117/200\n",
      "52/52 [==============================] - 19s 363ms/step - loss: 0.4388 - accuracy: 0.9242 - val_loss: 3.2134 - val_accuracy: 0.5110\n",
      "Epoch 118/200\n",
      "52/52 [==============================] - 19s 364ms/step - loss: 0.4353 - accuracy: 0.9228 - val_loss: 3.2405 - val_accuracy: 0.5116\n",
      "Epoch 119/200\n",
      "52/52 [==============================] - 19s 373ms/step - loss: 0.4296 - accuracy: 0.9262 - val_loss: 3.2620 - val_accuracy: 0.5092\n",
      "Epoch 120/200\n",
      "52/52 [==============================] - 19s 366ms/step - loss: 0.4212 - accuracy: 0.9270 - val_loss: 3.2383 - val_accuracy: 0.5116\n",
      "Epoch 121/200\n",
      "52/52 [==============================] - 19s 364ms/step - loss: 0.4287 - accuracy: 0.9267 - val_loss: 3.2564 - val_accuracy: 0.5122\n",
      "Epoch 122/200\n",
      "52/52 [==============================] - 19s 369ms/step - loss: 0.4242 - accuracy: 0.9260 - val_loss: 3.2755 - val_accuracy: 0.5039\n",
      "Epoch 123/200\n",
      "52/52 [==============================] - 19s 362ms/step - loss: 0.4198 - accuracy: 0.9293 - val_loss: 3.2487 - val_accuracy: 0.5056\n",
      "Epoch 124/200\n",
      "52/52 [==============================] - 19s 360ms/step - loss: 0.4193 - accuracy: 0.9291 - val_loss: 3.2716 - val_accuracy: 0.5104\n",
      "Epoch 125/200\n",
      "52/52 [==============================] - 19s 364ms/step - loss: 0.4170 - accuracy: 0.9293 - val_loss: 3.2902 - val_accuracy: 0.5003\n",
      "Epoch 126/200\n",
      "52/52 [==============================] - 19s 360ms/step - loss: 0.4149 - accuracy: 0.9307 - val_loss: 3.2620 - val_accuracy: 0.5080\n",
      "Epoch 127/200\n",
      "52/52 [==============================] - 19s 363ms/step - loss: 0.4130 - accuracy: 0.9300 - val_loss: 3.2972 - val_accuracy: 0.5134\n",
      "Epoch 128/200\n",
      "52/52 [==============================] - 19s 370ms/step - loss: 0.4079 - accuracy: 0.9321 - val_loss: 3.2776 - val_accuracy: 0.5068\n",
      "Epoch 129/200\n",
      "52/52 [==============================] - 19s 364ms/step - loss: 0.4017 - accuracy: 0.9346 - val_loss: 3.2974 - val_accuracy: 0.5068\n",
      "Epoch 130/200\n",
      "52/52 [==============================] - 22s 429ms/step - loss: 0.3974 - accuracy: 0.9347 - val_loss: 3.3027 - val_accuracy: 0.5050\n",
      "Epoch 131/200\n",
      "52/52 [==============================] - 20s 377ms/step - loss: 0.3958 - accuracy: 0.9362 - val_loss: 3.2927 - val_accuracy: 0.5169\n",
      "Epoch 132/200\n",
      "52/52 [==============================] - 29s 566ms/step - loss: 0.3920 - accuracy: 0.9391 - val_loss: 3.3027 - val_accuracy: 0.5068\n",
      "Epoch 133/200\n",
      "52/52 [==============================] - 21s 403ms/step - loss: 0.3919 - accuracy: 0.9363 - val_loss: 3.3203 - val_accuracy: 0.5045\n",
      "Epoch 134/200\n",
      "52/52 [==============================] - 23s 435ms/step - loss: 0.3866 - accuracy: 0.9395 - val_loss: 3.3462 - val_accuracy: 0.5068\n",
      "Epoch 135/200\n",
      "52/52 [==============================] - 21s 407ms/step - loss: 0.3842 - accuracy: 0.9389 - val_loss: 3.3259 - val_accuracy: 0.5128\n",
      "Epoch 136/200\n",
      "52/52 [==============================] - 23s 437ms/step - loss: 0.3810 - accuracy: 0.9426 - val_loss: 3.3325 - val_accuracy: 0.5211\n",
      "Epoch 137/200\n",
      "52/52 [==============================] - 25s 488ms/step - loss: 0.3845 - accuracy: 0.9424 - val_loss: 3.3565 - val_accuracy: 0.4914\n",
      "Epoch 138/200\n",
      "52/52 [==============================] - 29s 565ms/step - loss: 0.3796 - accuracy: 0.9418 - val_loss: 3.3172 - val_accuracy: 0.5086\n",
      "Epoch 139/200\n",
      "52/52 [==============================] - 28s 534ms/step - loss: 0.3775 - accuracy: 0.9435 - val_loss: 3.3331 - val_accuracy: 0.5151\n",
      "Epoch 140/200\n",
      "52/52 [==============================] - 25s 491ms/step - loss: 0.3755 - accuracy: 0.9448 - val_loss: 3.3671 - val_accuracy: 0.4967\n",
      "Epoch 141/200\n",
      "52/52 [==============================] - 66s 1s/step - loss: 0.3725 - accuracy: 0.9451 - val_loss: 3.3687 - val_accuracy: 0.5056\n",
      "Epoch 142/200\n",
      "52/52 [==============================] - 69s 1s/step - loss: 0.3654 - accuracy: 0.9453 - val_loss: 3.3873 - val_accuracy: 0.5009\n",
      "Epoch 143/200\n",
      "52/52 [==============================] - 34s 649ms/step - loss: 0.3644 - accuracy: 0.9471 - val_loss: 3.3703 - val_accuracy: 0.4955\n",
      "Epoch 144/200\n",
      "52/52 [==============================] - 40s 766ms/step - loss: 0.3702 - accuracy: 0.9432 - val_loss: 3.4271 - val_accuracy: 0.4861\n",
      "Epoch 145/200\n",
      "52/52 [==============================] - 45s 853ms/step - loss: 0.3587 - accuracy: 0.9482 - val_loss: 3.3555 - val_accuracy: 0.4997\n",
      "Epoch 146/200\n",
      "52/52 [==============================] - 45s 867ms/step - loss: 0.3667 - accuracy: 0.9444 - val_loss: 3.3822 - val_accuracy: 0.5086\n",
      "Epoch 147/200\n",
      "52/52 [==============================] - 45s 876ms/step - loss: 0.3618 - accuracy: 0.9473 - val_loss: 3.3695 - val_accuracy: 0.5021\n",
      "Epoch 148/200\n",
      "52/52 [==============================] - 40s 771ms/step - loss: 0.3524 - accuracy: 0.9493 - val_loss: 3.3689 - val_accuracy: 0.5009\n",
      "Epoch 149/200\n",
      "52/52 [==============================] - 58s 1s/step - loss: 0.3556 - accuracy: 0.9483 - val_loss: 3.3773 - val_accuracy: 0.5062\n",
      "Epoch 150/200\n",
      "52/52 [==============================] - 49s 931ms/step - loss: 0.3454 - accuracy: 0.9490 - val_loss: 3.4139 - val_accuracy: 0.5122\n",
      "Epoch 151/200\n",
      "52/52 [==============================] - 56s 1s/step - loss: 0.3503 - accuracy: 0.9488 - val_loss: 3.3717 - val_accuracy: 0.5116\n",
      "Epoch 152/200\n",
      "52/52 [==============================] - 43s 826ms/step - loss: 0.3509 - accuracy: 0.9510 - val_loss: 3.3845 - val_accuracy: 0.5116\n",
      "Epoch 153/200\n",
      "52/52 [==============================] - 74s 1s/step - loss: 0.3448 - accuracy: 0.9526 - val_loss: 3.3990 - val_accuracy: 0.5021\n",
      "Epoch 154/200\n",
      "52/52 [==============================] - 54s 1s/step - loss: 0.3431 - accuracy: 0.9533 - val_loss: 3.4138 - val_accuracy: 0.4938\n",
      "Epoch 155/200\n",
      "52/52 [==============================] - 40s 760ms/step - loss: 0.3394 - accuracy: 0.9542 - val_loss: 3.4211 - val_accuracy: 0.4950\n",
      "Epoch 156/200\n",
      "52/52 [==============================] - 37s 719ms/step - loss: 0.3379 - accuracy: 0.9542 - val_loss: 3.3801 - val_accuracy: 0.5110\n",
      "Epoch 157/200\n",
      "52/52 [==============================] - 39s 759ms/step - loss: 0.3382 - accuracy: 0.9524 - val_loss: 3.4039 - val_accuracy: 0.5027\n",
      "Epoch 158/200\n",
      "52/52 [==============================] - 38s 741ms/step - loss: 0.3385 - accuracy: 0.9536 - val_loss: 3.4065 - val_accuracy: 0.5110\n",
      "Epoch 159/200\n",
      "52/52 [==============================] - 42s 816ms/step - loss: 0.3325 - accuracy: 0.9549 - val_loss: 3.3778 - val_accuracy: 0.5092\n",
      "Epoch 160/200\n",
      "52/52 [==============================] - 35s 667ms/step - loss: 0.3364 - accuracy: 0.9542 - val_loss: 3.4035 - val_accuracy: 0.5104\n",
      "Epoch 161/200\n",
      "52/52 [==============================] - 33s 627ms/step - loss: 0.3300 - accuracy: 0.9567 - val_loss: 3.4619 - val_accuracy: 0.4938\n",
      "Epoch 162/200\n",
      "52/52 [==============================] - 33s 634ms/step - loss: 0.3333 - accuracy: 0.9540 - val_loss: 3.4209 - val_accuracy: 0.5068\n",
      "Epoch 163/200\n",
      "52/52 [==============================] - 34s 659ms/step - loss: 0.3277 - accuracy: 0.9572 - val_loss: 3.4634 - val_accuracy: 0.5033\n",
      "Epoch 164/200\n",
      "52/52 [==============================] - 33s 634ms/step - loss: 0.3209 - accuracy: 0.9584 - val_loss: 3.4442 - val_accuracy: 0.5003\n",
      "Epoch 165/200\n",
      "52/52 [==============================] - 33s 644ms/step - loss: 0.3306 - accuracy: 0.9562 - val_loss: 3.4609 - val_accuracy: 0.5080\n",
      "Epoch 166/200\n",
      "52/52 [==============================] - 35s 670ms/step - loss: 0.3239 - accuracy: 0.9578 - val_loss: 3.4773 - val_accuracy: 0.4932\n",
      "Epoch 167/200\n",
      "52/52 [==============================] - 38s 719ms/step - loss: 0.3213 - accuracy: 0.9583 - val_loss: 3.4171 - val_accuracy: 0.5134\n",
      "Epoch 168/200\n",
      "52/52 [==============================] - 31s 595ms/step - loss: 0.3201 - accuracy: 0.9579 - val_loss: 3.4698 - val_accuracy: 0.5003\n",
      "Epoch 169/200\n",
      "52/52 [==============================] - 30s 572ms/step - loss: 0.3232 - accuracy: 0.9562 - val_loss: 3.4439 - val_accuracy: 0.5027\n",
      "Epoch 170/200\n",
      "52/52 [==============================] - 30s 580ms/step - loss: 0.3084 - accuracy: 0.9614 - val_loss: 3.4237 - val_accuracy: 0.5139\n",
      "Epoch 171/200\n",
      "52/52 [==============================] - 31s 597ms/step - loss: 0.3103 - accuracy: 0.9602 - val_loss: 3.4212 - val_accuracy: 0.5092\n",
      "Epoch 172/200\n",
      "52/52 [==============================] - 31s 589ms/step - loss: 0.3196 - accuracy: 0.9594 - val_loss: 3.4563 - val_accuracy: 0.5050\n",
      "Epoch 173/200\n",
      "52/52 [==============================] - 30s 576ms/step - loss: 0.3142 - accuracy: 0.9596 - val_loss: 3.4476 - val_accuracy: 0.5110\n",
      "Epoch 174/200\n",
      "52/52 [==============================] - 30s 581ms/step - loss: 0.3126 - accuracy: 0.9589 - val_loss: 3.4388 - val_accuracy: 0.5080\n",
      "Epoch 175/200\n",
      "52/52 [==============================] - 30s 582ms/step - loss: 0.3141 - accuracy: 0.9592 - val_loss: 3.4975 - val_accuracy: 0.5039\n",
      "Epoch 176/200\n",
      "52/52 [==============================] - 30s 584ms/step - loss: 0.3100 - accuracy: 0.9590 - val_loss: 3.4693 - val_accuracy: 0.5110\n",
      "Epoch 177/200\n",
      "52/52 [==============================] - 30s 582ms/step - loss: 0.3142 - accuracy: 0.9589 - val_loss: 3.5400 - val_accuracy: 0.4837\n",
      "Epoch 178/200\n",
      "52/52 [==============================] - 30s 587ms/step - loss: 0.3147 - accuracy: 0.9595 - val_loss: 3.4837 - val_accuracy: 0.5104\n",
      "Epoch 179/200\n",
      "52/52 [==============================] - 31s 589ms/step - loss: 0.3039 - accuracy: 0.9634 - val_loss: 3.4776 - val_accuracy: 0.4973\n",
      "Epoch 180/200\n",
      "52/52 [==============================] - 31s 596ms/step - loss: 0.3034 - accuracy: 0.9619 - val_loss: 3.4702 - val_accuracy: 0.5086\n",
      "Epoch 181/200\n",
      "52/52 [==============================] - 28s 539ms/step - loss: 0.3050 - accuracy: 0.9596 - val_loss: 3.4746 - val_accuracy: 0.5104\n",
      "Epoch 182/200\n",
      "52/52 [==============================] - 30s 583ms/step - loss: 0.2988 - accuracy: 0.9649 - val_loss: 3.4527 - val_accuracy: 0.5068\n",
      "Epoch 183/200\n",
      "52/52 [==============================] - 31s 589ms/step - loss: 0.3022 - accuracy: 0.9630 - val_loss: 3.4843 - val_accuracy: 0.5033\n",
      "Epoch 184/200\n",
      "52/52 [==============================] - 31s 593ms/step - loss: 0.3004 - accuracy: 0.9643 - val_loss: 3.5004 - val_accuracy: 0.4955\n",
      "Epoch 185/200\n",
      "52/52 [==============================] - 31s 599ms/step - loss: 0.3028 - accuracy: 0.9603 - val_loss: 3.4732 - val_accuracy: 0.5134\n",
      "Epoch 186/200\n",
      "52/52 [==============================] - 31s 594ms/step - loss: 0.2964 - accuracy: 0.9627 - val_loss: 3.4586 - val_accuracy: 0.5145\n",
      "Epoch 187/200\n",
      "52/52 [==============================] - 31s 596ms/step - loss: 0.2937 - accuracy: 0.9623 - val_loss: 3.4910 - val_accuracy: 0.5080\n",
      "Epoch 188/200\n",
      "52/52 [==============================] - 31s 598ms/step - loss: 0.2962 - accuracy: 0.9624 - val_loss: 3.4709 - val_accuracy: 0.5056\n",
      "Epoch 189/200\n",
      "52/52 [==============================] - 31s 606ms/step - loss: 0.2923 - accuracy: 0.9627 - val_loss: 3.5031 - val_accuracy: 0.4944\n",
      "Epoch 190/200\n",
      "52/52 [==============================] - 31s 602ms/step - loss: 0.2929 - accuracy: 0.9641 - val_loss: 3.4787 - val_accuracy: 0.5045\n",
      "Epoch 191/200\n",
      "52/52 [==============================] - 32s 612ms/step - loss: 0.2907 - accuracy: 0.9654 - val_loss: 3.5451 - val_accuracy: 0.4973\n",
      "Epoch 192/200\n",
      "52/52 [==============================] - 31s 602ms/step - loss: 0.2957 - accuracy: 0.9625 - val_loss: 3.4889 - val_accuracy: 0.5009\n",
      "Epoch 193/200\n",
      "52/52 [==============================] - 32s 607ms/step - loss: 0.2910 - accuracy: 0.9651 - val_loss: 3.5203 - val_accuracy: 0.5027\n",
      "Epoch 194/200\n",
      "52/52 [==============================] - 32s 607ms/step - loss: 0.2879 - accuracy: 0.9676 - val_loss: 3.5074 - val_accuracy: 0.4991\n",
      "Epoch 195/200\n",
      "52/52 [==============================] - 33s 636ms/step - loss: 0.2907 - accuracy: 0.9634 - val_loss: 3.4893 - val_accuracy: 0.5098\n",
      "Epoch 196/200\n",
      "52/52 [==============================] - 30s 584ms/step - loss: 0.2885 - accuracy: 0.9671 - val_loss: 3.5105 - val_accuracy: 0.5098\n",
      "Epoch 197/200\n",
      "52/52 [==============================] - 28s 542ms/step - loss: 0.2887 - accuracy: 0.9649 - val_loss: 3.4707 - val_accuracy: 0.5128\n",
      "Epoch 198/200\n",
      "52/52 [==============================] - 30s 587ms/step - loss: 0.2923 - accuracy: 0.9631 - val_loss: 3.4585 - val_accuracy: 0.5104\n",
      "Epoch 199/200\n",
      "52/52 [==============================] - 32s 612ms/step - loss: 0.2846 - accuracy: 0.9670 - val_loss: 3.4689 - val_accuracy: 0.5128\n",
      "Epoch 200/200\n",
      "52/52 [==============================] - 32s 609ms/step - loss: 0.2863 - accuracy: 0.9659 - val_loss: 3.5038 - val_accuracy: 0.5098\n"
     ]
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "transformer.summary()\n",
    "historial = transformer.fit(dataset_train, epochs = 200, validation_data = dataset_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d8c7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:00:48.798733Z",
     "iopub.status.busy": "2023-03-19T19:00:48.798292Z",
     "iopub.status.idle": "2023-03-19T19:01:02.344011Z",
     "shell.execute_reply": "2023-03-19T19:01:02.343089Z"
    },
    "papermill": {
     "duration": 14.228796,
     "end_time": "2023-03-19T19:01:02.347498",
     "exception": false,
     "start_time": "2023-03-19T19:00:48.118702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, embedding_2_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output/model_spanish_kichwa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output/model_spanish_kichwa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "transformer.save('output/model_spanish_kichwa')\n",
    "\n",
    "# save the pares train to use on the server\n",
    "with open('output/pares_spanish_kichwa.txt', 'w') as f:\n",
    "    for par in pares_train:\n",
    "        par_string = ''.join(par)\n",
    "        f.write(par_string)\n",
    "        f.write('\\n')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d392b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:01:03.795429Z",
     "iopub.status.busy": "2023-03-19T19:01:03.794700Z",
     "iopub.status.idle": "2023-03-19T19:01:04.084503Z",
     "shell.execute_reply": "2023-03-19T19:01:04.083133Z"
    },
    "papermill": {
     "duration": 0.976011,
     "end_time": "2023-03-19T19:01:04.086839",
     "exception": false,
     "start_time": "2023-03-19T19:01:03.110828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f81b02ee9e0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('perdida')\n",
    "plt.plot(historial.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953ac073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:01:05.511549Z",
     "iopub.status.busy": "2023-03-19T19:01:05.510578Z",
     "iopub.status.idle": "2023-03-19T19:01:07.361279Z",
     "shell.execute_reply": "2023-03-19T19:01:07.360493Z"
    },
    "papermill": {
     "duration": 2.601532,
     "end_time": "2023-03-19T19:01:07.364634",
     "exception": false,
     "start_time": "2023-03-19T19:01:04.763102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoja de diÃ¡logo nÃºmero tres \n",
      "[start] kimsaniki parlanakuymanta panka [end]\n",
      "...\n",
      "treinta y sÃ©is \n",
      "[start] kimsa chunka sukta [end]\n",
      "...\n",
      "siembro papa cafÃ© \n",
      "[start] pullu papata tarpuni [end]\n",
      "...\n",
      "yo tambiÃ©n les quiero a ustedes\n",
      "[start] Ã±ukapish kankunata kuyani [end]\n",
      "...\n",
      "mil cuarenta y dos \n",
      "[start] waranka chusku chunka ishkay [end]\n",
      "...\n",
      "aviÃ³n\n",
      "[start] wawki [end]\n",
      "...\n",
      "besar\n",
      "[start] muchana [end]\n",
      "...\n",
      "cuarenta y sÃ©is\n",
      "[start] chusku chunka sukta [end]\n",
      "...\n",
      "esperame en la vertiente de agua\n",
      "[start] yaku pukyupi chapanki [end]\n",
      "...\n",
      "ayer si fuiste a la comunidad \n",
      "[start] kaynaka llaktaman rirkankichu [end]\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "vocab_kichwa = texto_target_vectorizado.get_vocabulary()\n",
    "busqueda_kichwa = dict(zip(range(len(vocab_kichwa)), vocab_kichwa))\n",
    "max_len_sentence = 7\n",
    "\n",
    "\n",
    "def traducir(input_sentence):\n",
    "    tokenized_input_sentence = texto_source_vectorizado([input_sentence])\n",
    "    sentence_decoded = \"[start]\"\n",
    "    for i in range(max_len_sentence):\n",
    "        sentence_target_tokenized = texto_target_vectorizado(\n",
    "            [sentence_decoded])[:, :-1]\n",
    "        predicciones = transformer(\n",
    "            [tokenized_input_sentence, sentence_target_tokenized])\n",
    "        index_token = np.argmax(predicciones[0, i, :])\n",
    "        token = busqueda_kichwa[index_token]\n",
    "        sentence_decoded += \" \" + token\n",
    "        if token == \"[end]\":\n",
    "            break\n",
    "    return sentence_decoded\n",
    "\n",
    "test_spanish_texts = [pair[0] for pair in pares_train]\n",
    "\n",
    "for _ in range(10):\n",
    "    input_sentence = random.choice(test_spanish_texts)\n",
    "    print(input_sentence)\n",
    "    print(traducir(input_sentence))\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e8c81f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T19:01:08.826525Z",
     "iopub.status.busy": "2023-03-19T19:01:08.825318Z",
     "iopub.status.idle": "2023-03-19T19:01:08.933076Z",
     "shell.execute_reply": "2023-03-19T19:01:08.931766Z"
    },
    "papermill": {
     "duration": 0.871847,
     "end_time": "2023-03-19T19:01:08.935909",
     "exception": false,
     "start_time": "2023-03-19T19:01:08.064062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] ashata [end]\n"
     ]
    }
   ],
   "source": [
    "print(traducir(\"hola\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4082.746343,
   "end_time": "2023-03-19T19:01:13.021109",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-19T17:53:10.274766",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f650c42177d71d9d442d1237f6fd42533fcf5dfc49185c5979f4d948a86906b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
